{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24255974",
   "metadata": {},
   "source": [
    "# AI-Based Demand-Supply Matching Engine\n",
    "This notebook simulates a supply chain engine using:\n",
    "- Linear Programming (LP)\n",
    "- Q-Learning (Tabular RL)\n",
    "- PPO (Stable-Baselines3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "def generate_weekly_supply_demand(n_regions=3, n_weeks=10, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    data = []\n",
    "    for week in range(n_weeks):\n",
    "        for region in range(n_regions):\n",
    "            demand = np.random.randint(50, 150)\n",
    "            priority = np.random.uniform(0.5, 1.5)\n",
    "            data.append({\n",
    "                \"Week\": week,\n",
    "                \"Region\": f\"Region_{region+1}\",\n",
    "                \"Demand\": demand,\n",
    "                \"Priority\": priority\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = generate_weekly_supply_demand()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398bb83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linear_programming_allocation(df_week, total_supply):\n",
    "    demand = df_week[\"Demand\"].values\n",
    "    cost = 1 / df_week[\"Priority\"].values\n",
    "    bounds = [(0, d) for d in demand]\n",
    "    A_eq = [np.ones(len(demand))]\n",
    "    b_eq = [min(total_supply, sum(demand))]\n",
    "    result = linprog(c=cost, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method=\"highs\")\n",
    "    allocation = np.round(result.x).astype(int) if result.success else np.zeros(len(demand), dtype=int)\n",
    "    df_week[\"Allocated_LP\"] = allocation\n",
    "    df_week[\"Unmet_LP\"] = df_week[\"Demand\"] - allocation\n",
    "    df_week[\"FillRate_LP\"] = allocation / df_week[\"Demand\"]\n",
    "    return df_week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096afd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QLearningAgentLocal:\n",
    "    def __init__(self, n_regions, n_supply_levels, alpha=0.1, gamma=0.95, epsilon=0.1):\n",
    "        self.n_regions = n_regions\n",
    "        self.n_supply_levels = n_supply_levels\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_table = {}\n",
    "\n",
    "    def get_state_key(self, state):\n",
    "        return tuple(state.tolist())\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        key = self.get_state_key(state)\n",
    "        if key not in self.q_table:\n",
    "            self.q_table[key] = np.random.rand(*(self.n_supply_levels,) * self.n_regions)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(0, self.n_supply_levels, size=self.n_regions)\n",
    "        else:\n",
    "            return np.unravel_index(np.argmax(self.q_table[key]), self.q_table[key].shape)\n",
    "\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        key = self.get_state_key(state)\n",
    "        next_key = self.get_state_key(next_state)\n",
    "        if key not in self.q_table:\n",
    "            self.q_table[key] = np.zeros((self.n_supply_levels,) * self.n_regions)\n",
    "        if next_key not in self.q_table:\n",
    "            self.q_table[next_key] = np.zeros((self.n_supply_levels,) * self.n_regions)\n",
    "        idx = tuple(action)\n",
    "        best_next = np.max(self.q_table[next_key])\n",
    "        self.q_table[key][idx] += self.alpha * (reward + self.gamma * best_next - self.q_table[key][idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460425b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_results = []\n",
    "agent = QLearningAgentLocal(n_regions=3, n_supply_levels=5)\n",
    "total_supply = 300\n",
    "\n",
    "for week in range(10):\n",
    "    df_week = df[df[\"Week\"] == week].copy().reset_index(drop=True)\n",
    "    df_week = linear_programming_allocation(df_week, total_supply)\n",
    "    demand = df_week[\"Demand\"].values\n",
    "    state = (demand // 10).astype(int)\n",
    "    action = np.array(agent.choose_action(state))\n",
    "    allocation = np.minimum(action * (total_supply // 5), demand)\n",
    "    df_week[\"Allocated_Q\"] = allocation\n",
    "    df_week[\"Unmet_Q\"] = df_week[\"Demand\"] - allocation\n",
    "    df_week[\"FillRate_Q\"] = df_week[\"Allocated_Q\"] / df_week[\"Demand\"]\n",
    "    reward = df_week[\"FillRate_Q\"].mean()\n",
    "    agent.update(state, action, reward, state)\n",
    "    df_results.append(df_week)\n",
    "\n",
    "df_final = pd.concat(df_results)\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9cc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_kpis = df_final.groupby(\"Week\").agg({\n",
    "    \"FillRate_LP\": \"mean\",\n",
    "    \"FillRate_Q\": \"mean\",\n",
    "    \"Unmet_LP\": \"sum\",\n",
    "    \"Unmet_Q\": \"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_kpis[\"Week\"], df_kpis[\"FillRate_LP\"], label=\"LP Fill Rate\", marker='o')\n",
    "plt.plot(df_kpis[\"Week\"], df_kpis[\"FillRate_Q\"], label=\"Q-Learning Fill Rate\", marker='x')\n",
    "plt.title(\"Fill Rate: LP vs Q-Learning\")\n",
    "plt.xlabel(\"Week\"); plt.ylabel(\"Avg Fill Rate\")\n",
    "plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_kpis[\"Week\"], df_kpis[\"Unmet_LP\"], label=\"LP Unmet\", marker='o')\n",
    "plt.plot(df_kpis[\"Week\"], df_kpis[\"Unmet_Q\"], label=\"Q Unmet\", marker='x')\n",
    "plt.title(\"Unmet Demand: LP vs Q-Learning\")\n",
    "plt.xlabel(\"Week\"); plt.ylabel(\"Unmet Demand\")\n",
    "plt.legend(); plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0297bf",
   "metadata": {},
   "source": [
    "### PPO Agent via Stable-Baselines3\n",
    "To run PPO training:\n",
    "```\n",
    "pip install stable-baselines3[extra] gym\n",
    "```\n",
    "Then define `SupplyMatchingEnv` as shown previously and train using PPO."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}